# SEVI 第二阶段大作业
[toc]
# 第二次尝试: 双球壳 v2.0

## 数据集
- `data/gen_pic_double.ipynb`文件,生成`data_double.h5`数据文件
- 将初步尝试中的电子位置投射在 $1024 \times 1024$ 的矩阵上, 矩阵每个位置表示该位置有多少个电子打在上面.

- 将两个但球壳矩阵相加, 除以数量总和归一化, 再乘以255, 便于观察图像.

- 生成了3000个数据, 将1/10用作验证集

## 训练效果

- 训练过程较单球壳慢, 约100个epoch后, loss下降到0.01以下

- 效果和单球壳的结果一样好, 可以平均化相对误差达到7%, 证明该模型有效.

- 平均化相对误差:

    认为每个参数位置绝对误差相同, 根据平均loss计算得误差后, 除以0.7(与单球壳第一个个参数的数值相近)

    可以作为模型好坏的评价标准

- 局限性:

    1000个数据较少, 会导致模型泛化能力不够

    由于数据点为1000个单球壳的组合, 验证集中会出现训练集的数据, 导致模型过拟合,

    下一步尝试自己生成数据集

(模型训练过于复杂, 未完整保存过程)






# 第一次尝试 v1.0

将第二类数据集的每个球壳(能级)的电子找出来, 复原为图像, 从图像中识别分布信息

先尝试从单球壳中求分布

## 数据名

原始数据为`train{num}.h5`, 将电子位置,半径,球壳的beta存为`dataset_{num}.h5`

单球壳图像:

![单球壳图像](figures/README_figures/gen_pic_single.png)

## 训练模型

使用`torchvision`的`resnet`模型, 包括18, 34, 101

## 模型

将resnet输入通道变为1, 最后线性层fc变为(512,12), 即最后输出为12个参数, 对应单球壳的beta分布前12个参数

## loss函数

loss函数定义如下:
```python
def loss_func(input,label):
    rate = 2/(np.array(range(1,13))*4+1)
    rate = torch.Tensor(rate)
    delta = input - label
    return torch.sum(torch.sum((delta**2 * rate),dim=1))/len(input)
```
即相比于评测函数, 这里少了求平方根的一步

两种评估对比较结果好坏是近乎相同的, 但这里计算量更小

## 训练方式

将第二类训练集的1000种数据分为训练集(900)和验证集(100)

由于训练过程较长, epoch较多, 训练过程并未保存完全, 大致情况为: 

resnet18: 

训练所需epoch较多, 在50个epoch之后loss偶有下降到0.01以下, 200个epoch后能下降到1e-5以下

resnet34,101:

100个epoch不能看出明显下降, 故放弃训练


## 设备信息

显卡: A100-SXM4-40GB 

Cpu: AMD EPYC 7302 16-Core Processor

训练时长: > 1min/epoch

## 评估

我认为单球壳的结果表明模型能提取到分布信息. 
根据loss结果, 平均到每个参数, 误差可以小于5%. 
下一步可以将两个球壳合并进行训练

